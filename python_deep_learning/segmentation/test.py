import argparse
import glob
import numpy as np
import PIL as pil
import torch

import loader.utility as utility
import models.link_net as segment_models
import transformer.transform_policy as transform_policy

from torch.autograd import Variable
from PIL.Image import Image

parser = argparse.ArgumentParser(description = 'Hyper parameters')

parser.add_argument('--camvid_folder', type = str, default = '/home/ramsus/Qt/computer_vision_dataset/segmentation/camvid/',
                    help = 'This folder should contains the files and folders clone from https://github.com/mostafaizz/camvid and '
                    'the files and folders generated by script process_camvid_data.py')
parser.add_argument('--model', type = str, help = 'Location of model binary')

args = vars(parser.parse_args())
        
def decode_segmap(gray_img, label_colors):    
    label_colours = np.array(label_colors)
    r = gray_img.copy()
    g = gray_img.copy()
    b = gray_img.copy()
    for l in range(len(label_colors)):
        mask = gray_img == l
        r[mask] = label_colours[l, 0]
        g[mask] = label_colours[l, 1]
        b[mask] = label_colours[l, 2]

    rgb = np.zeros((gray_img.shape[0], gray_img.shape[1], 3))
    rgb[:, :, 0] = r
    rgb[:, :, 1] = g
    rgb[:, :, 2] = b
    
    return rgb

def to_segmap(model, raw_img_name, label_colors, size = None):
    img = pil.Image.open(raw_img_name)
    if size:
        img = img.resize(size)
    img = np.array(img).astype('float32')
    normalizer = transform_policy.normalize()
    img = normalizer(img)

    img = img.transpose(2,0,1)
    img = np.expand_dims(img, 0)
    img = torch.from_numpy(img)    

    img = Variable(img.cuda())
    output = model(img)
    
    #max function return values of max at axis 1 and their index
    #we need to get the index with maximum value for our purpose
    output = output.data.max(1)[1].cpu().numpy()
    output = np.squeeze(output)    

    rgb = decode_segmap(output, label_colors)
    
    return rgb.astype('uint8')

def test_images_accuracy(model, raw_img_folder, label_folder, label_colors):
    raw_imgs_loc = list(glob.glob(raw_img_folder + "/*.png"))
    label_len = len(label_colors)    
    iou = np.zeros((label_len))
    mean_acc = 0
    for i, img_loc in enumerate(raw_imgs_loc):
        print(i, ":caculate accuracy of image:", img_loc)
        segmap = to_segmap(model, img_loc, label_colors)
        label = pil.Image.open(label_folder + "/" + img_loc.split("/")[-1][0:-4] + "_L.png")
        label = np.array(label)
        mean_acc += (segmap == label).mean()
        for i, color in enumerate(label_colors):
            real_mask = label[:,:,] == color
            predict_mask = segmap[:,:,] == color
            true_intersect_mask = (real_mask & predict_mask)
            
            TP = true_intersect_mask.sum() #true positive
            FP = predict_mask.sum() - TP #false positive
            FN = real_mask.sum() - TP  #false negative            
            #print("TP, FP, FN", TP, FP, FN)
            iou[i] += TP/float(TP + FP + FN)
            
    return iou / len(raw_imgs_loc), mean_acc / len(raw_imgs_loc)
    
label_colors = utility.read_color_integer(args['camvid_folder'] + '/label_integer.txt')
model = segment_models.link_net(len(label_colors))
model.load_state_dict(torch.load(args['model']))
model.cuda()

iou, mean_acc = test_images_accuracy(model, args['camvid_folder'] + "/test_raws/", 
                                     args['camvid_folder'] + "/test_labels/",
                                     label_colors)
print("mean acc:", mean_acc)
color_info = utility.read_color_count_sorted(args['camvid_folder'] + 'color_count_train_sorted.txt')
color_info = { (data[0], data[1], data[2]): data[5] for data in color_info}
for i, color in enumerate(label_colors):
    print("iou of", color_info[color], "is", iou[i])
print("average iou:", iou.mean())    
