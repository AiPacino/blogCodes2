import argparse
import math
import matplotlib.pyplot as plt
import numpy as np
import multiprocessing
import PIL as pil
import time
import torch
import torch.autograd as autograd
import torch.nn as nn

import sys
sys.path.append('loader/')

import loader.camvid_loader as camvid_loader
import loader.utility as utility
import loss.loss as loss_2d
import lr_scheduling
import models.link_net as segment_models
import transformer.transform_policy as transform_policy
import visualize

from torch.autograd import Variable
from torchvision import transforms, utils

parser = argparse.ArgumentParser(description = 'Hyper parameters')

parser.add_argument('--camvid_folder', type = str, default = "/home/ramsus/Qt/computer_vision_dataset/segmentation/camvid/",
                    help = 'This folder should contains the files and folders clone from https://github.com/mostafaizz/camvid and '
                    'the files and folders generated by script process_camvid_data.py')
parser.add_argument('--epoch', type = int, default = 800, help = 'Number of epoch')
parser.add_argument('--batch_size', type = int, default = 16, help = 'Batch of training set')
parser.add_argument('--init_lr', type = float, default = 5e-4, help = 'Initial learning rate')
parser.add_argument('--optimizer', type = str, default = "RMSprop", help = 'Optimizer type, could be Adam, RMSprop or SGD')
parser.add_argument('--cache', type = str, default = 'y', help = 'True will load and cache the training images and labels in ram.'
                    'False will load the images and labels everytime')
parser.add_argument('--save_model_as', type = str, default = 'link_net', help = 'The name of model being saved')
parser.add_argument('--save_per_epoch', type = int, default = 200, help = 'Save the model after epoch % args[save_per_epoch] == 0')
parser.add_argument('--random_crop_height', type = int, default = 320, help = 'Random crop height')
parser.add_argument('--random_crop_width', type = int, default = 480, help = 'Random crop width')
parser.add_argument('--weighthing', type = str, default = 'y', help = 'True will adopt weights on loss function and vice versa')

args = vars(parser.parse_args())

def str_to_bool(v):
    if v.lower() in ('yes', 'true', 't', 'y', '1'):
        return True
    elif v.lower() in ('no', 'false', 'f', 'n', '0'):
        return False
    else:
        raise argparse.ArgumentTypeError('Boolean value expected.')

#read_color_integer read the rgb value from label_integer.txt, this file store the rgb
#value according to the order of label.
label_colors = utility.read_color_integer(args['camvid_folder'] + "label_integer.txt")

#create loader of camvid dataset    
random_crop = transform_policy.random_crop((args['random_crop_height'], args['random_crop_width']), copy = str_to_bool(args['cache']))
transform_func = transforms.Compose([random_crop, transform_policy.flip_horizontal(), transform_policy.to_tensor()])
normalizer = transform_policy.normalize(copy = False)
loader = camvid_loader.create_camvid_loader(args['camvid_folder'] + "train_raws/", 
                                            args['camvid_folder'] + "train_int_labels/", 
                                            transform_func, normalizer, cache = str_to_bool(args['cache']))

#create link net model
model = segment_models.link_net(len(label_colors))
data_loader = torch.utils.data.DataLoader(loader, batch_size = args['batch_size'], shuffle = True, num_workers = multiprocessing.cpu_count())

#build a dictionary with key = (r,g,b), value = percentage of color
color_info = utility.read_color_count_sorted(args['camvid_folder'] + 'color_count_train_sorted.txt')
color_info = { (data[0], data[1], data[2]): data[4] for data in color_info}

#build the weights matrix according to the formula 1/ln(1.02 + w)
weights = None
if str_to_bool(args['weighthing']):
    print("set weights")
    weights = []
    for color in label_colors:
        w = color_info[color]
        w = 1 / math.log(1.02 + w, 2)
        weights.append(w)

    weights = np.array(weights)
    weights = torch.from_numpy(weights.astype('float32')).cuda()
else:
    print("zero weights")

def train(model, loader, weights, epoch, lr_rate, save_model_as):    
    model.cuda()
    model.train(True)
    best_loss = 99999999
    loss_func = loss_2d.cross_entropy_loss_2d(weights)
    optimizer = None
    best_model_epoch = 0
    if args['optimizer'].lower() == 'adam':
        optimizer = torch.optim.Adam(model.parameters(), lr = lr_rate)
    elif args['optimizer'].lower() == 'rmsprop':
        optimizer = torch.optim.RMSprop(model.parameters(), lr = lr_rate)
    elif args['optimizer'].lower() == 'sgd':
        optimizer = torch.optim.SGD(model.parameters(), lr = lr_rate)
    else:
        raise Exception('Wrong optimizer, please pick you optimizer within Adam, RMSprop and SGD')
    
    #plot_2d update the loss graph every epoch
    plot = visualize.plot_2d(min_x = 0, max_x = epoch)    
    for e in range(epoch):        
        aggr_loss = 0
        for i, samples in enumerate(loader):            
            raws, labels = Variable(samples['raw']), Variable(samples['label'])
            raws, labels = raws.cuda(), labels.cuda()
        
            optimizer.zero_grad()
        
            output = model(raws)        
            loss = loss_func(output, labels)
            aggr_loss += loss.data[0]
            
            print("epoch:", e, "batch:", i+1, "aggregate loss:", aggr_loss / (i + 1), "loss:", loss.data[0])
            
            loss.backward()
            optimizer.step()
            
            iter_num = len(loader)*e + i
            lr_scheduling.poly_lr_scheduler(optimizer, lr_rate, iter_num)
                
        plot.update(e + 1, aggr_loss / len(loader))
        
        #save the model with smallest loss
        if aggr_loss/(len(loader)) < best_loss:
            best_loss = aggr_loss
            torch.save(model.state_dict(), save_model_as + "_epoch_best_model.tch")
            best_model_epoch = e
        #save the model every 200 epoch
        if (e != 0) and (e % args['save_per_epoch'] == 0):
            torch.save(model.state_dict(), save_model_as + "_{}_epoch.tch".format(e))            
           
    plot.savefig(save_model_as + "_{}_epoch.png".format(epoch))
    torch.save(model.state_dict(), save_model_as + "_{}_epoch.tch".format(epoch))
    print('best model occur at epoch:', e, ' aggregate loss is:', aggr_loss/(len(loader)))
    
    return model

start_time = time.time()
train(model, data_loader, weights, args['epoch'], args['init_lr'], args['save_model_as'])
elapsed_time = time.time() - start_time
print("elapsed time:", elapsed_time)
